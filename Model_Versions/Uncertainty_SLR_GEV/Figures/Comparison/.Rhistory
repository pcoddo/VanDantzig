graphics.off()
# Read read mileage data and remove incomplete entries (NA)
df = read.csv("Cars_mileage.csv",
header = T,
sep = ",",
na.strings = '?')
df = na.omit(df)
# Add variable for median mileage
df$mpg_binary = NA
# Apply binary classification
df$mpg_binary = sapply(1:length(df$mpg), function(x){
if(df$mpg[x] >= median(df$mpg)){
return(1)
} else {
return(0)
}
})
### Ensure data is properly formatted
# Reclassify discrete categorical variables as factor
cat_var = c("cylinders", "origin", "year", "name", "mpg_binary")
for(i in cat_var){
df[ ,i] = as.factor(df[ ,i])
}
# Reclassify continuous variables as numeric
num_var = c("displacement", "horsepower", "weight", "acceleration")
for(i in num_var){
df[ ,i] = as.numeric(df[ ,i])
}
# Check data structure
print(str(df))
### Visualize variable relationships
# Load required packages
require(GGally)
require(ggplot2)
# Subset predictor variables to plot and save as new data frame
df_original = df
df = subset(x = df, select = c("mpg", "cylinders", "displacement", "horsepower", "weight",
"acceleration", "year", "mpg_binary"))
# Produce pairs plot
#png("Figures/Figure1_pairsPlot.png", width = 8, height = 5.5, units = 'in', res = 300)
f1 = ggpairs(df,
mapping = ggplot2::aes(color = mpg_binary),
upper = list(continuous = wrap("density", alpha = 0.5)),
lower = list(continuous = wrap("points", alpha = 0.3), combo = wrap("dot", alpha = 0.4)),
diag = list(continuous = wrap("densityDiag", alpha = 0.5)),
title = "Figure 1. Vehicle variable pairs plot",
legend = c(1,1)) +
theme(legend.position = "right")
f1
# Load library
require(tidyr)
# Plot mpg against other continuous variables
#png("Figures/Figure2_mpgPlots.png", width = 6.5, height = 4.5, units = 'in', res = 300)
f2 = df[ ,c("mpg", "displacement", "horsepower", "weight", "acceleration", "mpg_binary")] %>%
gather(-mpg, -mpg_binary, key = "var", value = value) %>%
ggplot(aes(x = value, y = mpg)) +
geom_point(aes(color = mpg_binary)) +
facet_wrap(~var, scales = "free", nrow = 2) +
geom_smooth(method = "lm") +
theme_bw() +
ggtitle("Figure 2. MPG Plots - Continuous variables")
f2
#png("Figures/Figure3_mpgPlots_log.png", width = 6.5, height = 4.5, units = 'in', res = 300)
f3 = df[ ,c("mpg", "displacement", "horsepower", "weight", "acceleration", "mpg_binary")] %>%
gather(-mpg, -mpg_binary, key = "var", value = value) %>%
ggplot(aes(x = value, y = log10(mpg))) +
geom_point(aes(color = mpg_binary)) +
facet_wrap(~var, scales = "free", nrow = 2) +
geom_smooth(method = "lm") +
theme_bw() +
ggtitle("Figure 3. MPG Plots - Log scale")
f3
# Categorical relationships
#png("Figures/Figure4_mpgPlots_categorical.png", width = 6.5, height = 4.5, units = 'in', res = 300)
f4 = df[ ,c("mpg", "cylinders", "year", "mpg_binary")] %>%
gather(-mpg, -mpg_binary, key = "var", value = value) %>%
ggplot(aes(x = value, y = mpg)) +
geom_point(aes(color = mpg_binary)) +
facet_wrap(~var, scales = "free", nrow = 2) +
geom_smooth(method = "lm") +
theme_bw() +
ggtitle("Figure 4. MPG Plots - Categorical variables")
f4
# Find proporiton of cars with median-exceeding fuel economies for each year
proportion = vector("integer")
for(i in levels(df$year)){
above = which(df$mpg_binary == 1)
proportion[i] = length((which(df$year[above] == i))) /
length((which(df$year == i))) * 100
}
#print(proportion, digits = 3)
# Remove mpg variable from data frame
df = df[ ,2:ncol(df)]
# Randomize dataset by assigning indices random numbers
set.seed(90210)
rand = runif(nrow(df))
df = df[order(rand), ]
# Create test (n = 40) and training (n = 352) sets from data frame
df_test = df[1:40, ]
df_train = df[41:nrow(df), ]
# Load library
require(class)
# Normalize variables to range from 0 to 1 to remove influence of different variable ranges
# Create new normalized data frame for continuous predictor variables (columns 2:5)
normalize = function(x){
return((x - min(x)) / (max(x) - min(x)))
}
df_test_continuous = as.data.frame(sapply(df_test[ ,num_var], normalize))
df_train_continuous = as.data.frame(sapply(df_train[ ,num_var], normalize))
# Confirm new data structure
print(summary(df_test_continuous))
print(summary(df_train_continuous))
# Create data frames for target variable (mpg_binary) prediction
df_test_target = df[1:40, "mpg_binary"]
df_train_target = df[41:nrow(df), "mpg_binary"]
# Set k value
k = floor(sqrt(nrow(df)))
# Create model
knn_mod = knn(train = df_train_continuous, test = df_test_continuous, cl = df_train_target, k = k, prob = T)
# Create table to visualize model results
# table(df_test_target, knn_mod)
# Load library
require(rpart)
require(rpart.plot)
# Specify target variable
tree_mod <- rpart(mpg_binary ~., data = df_train, method = "class")
### Plot model results
#png("Figures/Figure5_TreeA.png", width = 4, height = 4, units = 'in', res = 300)
rpart.plot(tree_mod, type = 3, digits = 3, fallen.leaves = TRUE)
tree_mod$variable.importance
table(tree_mod$variable.importance)
names(tree_mod$variable.importance)
table(names(tree_mod$variable.importance),tree_mod$variable.importance)
dim(tree_mod$variable.importance)
str(tree_mod$variable.importance)
print(tree_mod$variable.importance)
# Load library
require(rpart)
require(rpart.plot)
# Specify target variable
tree_mod <- rpart(mpg_binary ~., data = df_train, method = "class")
### Plot model results
#png("Figures/Figure5_TreeA.png", width = 4, height = 4, units = 'in', res = 300)
rpart.plot(tree_mod, type = 3, digits = 3, fallen.leaves = TRUE)
# Print most important variabes
print(tree_mod$variable.importance)
print(tree_mod$variable.importance)
# Re-run model to exclude categorical variables
# Re-combine continuous training set with 'mpg_binary' variable
df_test_continuous = data.frame(df_test[ ,num_var])
df_train_continuous = data.frame(df_train[ ,num_var], df_train$mpg_binary)
colnames(df_train_continuous)[5] = "mpg_binary"
tree_mod2 <- rpart(mpg_binary ~., data = df_train_continuous)
### Plot new results
#png("Figures/Figure6_TreeB.png", width = 4, height = 4, units = 'in', res = 300)
rpart.plot(tree_mod2, type = 3, digits = 3, fallen.leaves = TRUE)
tree_mod2$variable.importance
print(tree_mod_2$variable.importance)
print(tree_mod2$variable.importance)
tree_mod_test <- predict(tree_mod2, df_test_continuous, type = "class")
tree_mod_test2 <- predict(tree_mod, df_test, type = "class")
table(df_test_target, tree_mod_test)
table(df_test_target, tree_mod_test2)
tree_mod_test2 <- predict(tree_mod2, df_test_continuous, type = "class")
table(df_test_target, tree_mod_test2)
39/40
1/40
# Randomize original dataset by assigning indices random numbers
set.seed(90210)
rand = runif(nrow(df_original))
df_all = df_original[order(rand), c(1:7, 10)]
# Create test (n = 40) and training sets from original data frame
df_test = df_all[1:40, ]
df_train = df_all[41:nrow(df), ]
# Specify target variable
tree_mod3 <- rpart(mpg_binary ~., data = df_train, method = "class")
### Plot model results
#png("Figures/Figure7_allVars.png", width = 4, height = 4, units = 'in', res = 300)
rpart.plot(tree_mod3, type = 3, digits = 3, fallen.leaves = TRUE)
tree_mod_test3 <- predict(tree_mod3, df_test, type = "class")
table(df_test_target, tree_mod_test3)
# Randomize original dataset by assigning indices random numbers
set.seed(90210)
rand = runif(nrow(df_original))
df_all = df_original[order(rand), c(1:7, 10)]
# Create test (n = 40) and training sets from original data frame
df_test = df_all[1:40, ]
df_train = df_all[41:nrow(df), ]
# Specify target variable
tree_mod3 <- rpart(mpg_binary ~., data = df_train, method = "class")
### Plot model results
#png("Figures/Figure7_allVars.png", width = 4, height = 4, units = 'in', res = 300)
rpart.plot(tree_mod3, type = 3, digits = 3, fallen.leaves = TRUE)
# Predict based on model with all variables included
tree_mod_test3 <- predict(tree_mod3, df_test, type = "class")
table(df_test_target, tree_mod_test3)
tree_mod3$variable.importance
rm(list = ls())
graphics.off()
df = read.csv("Cars_mileage.csv",
header = T,
sep = ",",
na.strings = '?')
df = na.omit(df)
df$mpg_binary = NA
df$mpg_binary = sapply(1:length(df$mpg), function(x){
if(df$mpg[x] >= median(df$mpg)){
return(1)
} else {
return(0)
}
})
cat_var = c("cylinders", "origin", "year", "name", "mpg_binary")
for(i in cat_var){
df[ ,i] = as.factor(df[ ,i])
}
num_var = c("displacement", "horsepower", "weight", "acceleration")
for(i in num_var){
df[ ,i] = as.numeric(df[ ,i])
}
print(str(df))
require(GGally)
require(ggplot2)
df_original = df
df = subset(x = df, select = c("mpg", "cylinders", "displacement", "horsepower", "weight",
"acceleration", "year", "mpg_binary"))
f1 = ggpairs(df,
mapping = ggplot2::aes(color = mpg_binary),
upper = list(continuous = wrap("density", alpha = 0.5)),
lower = list(continuous = wrap("points", alpha = 0.3), combo = wrap("dot", alpha = 0.4)),
diag = list(continuous = wrap("densityDiag", alpha = 0.5)),
title = "Figure 1. Vehicle variable pairs plot",
legend = c(1,1)) +
theme(legend.position = "right")
f1
require(tidyr)
f2 = df[ ,c("mpg", "displacement", "horsepower", "weight", "acceleration", "mpg_binary")] %>%
gather(-mpg, -mpg_binary, key = "var", value = value) %>%
ggplot(aes(x = value, y = mpg)) +
geom_point(aes(color = mpg_binary)) +
facet_wrap(~var, scales = "free", nrow = 2) +
geom_smooth(method = "lm") +
theme_bw() +
ggtitle("Figure 2. MPG Plots - Continuous variables")
f2
f3 = df[ ,c("mpg", "displacement", "horsepower", "weight", "acceleration", "mpg_binary")] %>%
gather(-mpg, -mpg_binary, key = "var", value = value) %>%
ggplot(aes(x = value, y = log10(mpg))) +
geom_point(aes(color = mpg_binary)) +
facet_wrap(~var, scales = "free", nrow = 2) +
geom_smooth(method = "lm") +
theme_bw() +
ggtitle("Figure 3. MPG Plots - Log scale")
f3
f4 = df[ ,c("mpg", "cylinders", "year", "mpg_binary")] %>%
gather(-mpg, -mpg_binary, key = "var", value = value) %>%
ggplot(aes(x = value, y = mpg)) +
geom_point(aes(color = mpg_binary)) +
facet_wrap(~var, scales = "free", nrow = 2) +
geom_smooth(method = "lm") +
theme_bw() +
ggtitle("Figure 4. MPG Plots - Categorical variables")
f4
proportion = vector("integer")
for(i in levels(df$year)){
above = which(df$mpg_binary == 1)
proportion[i] = length((which(df$year[above] == i))) /
length((which(df$year == i))) * 100
}
print(proportion, digits = 3)
df = df[ ,2:ncol(df)]
set.seed(90210)
rand = runif(nrow(df))
df = df[order(rand), ]
df_test = df[1:40, ]
df_train = df[41:nrow(df), ]
require(class)
normalize = function(x){
return((x - min(x)) / (max(x) - min(x)))
}
df_test_continuous = as.data.frame(sapply(df_test[ ,num_var], normalize))
df_train_continuous = as.data.frame(sapply(df_train[ ,num_var], normalize))
print(summary(df_test_continuous))
print(summary(df_train_continuous))
df_test_target = df[1:40, "mpg_binary"]
df_train_target = df[41:nrow(df), "mpg_binary"]
k = floor(sqrt(nrow(df)))
knn_mod = knn(train = df_train_continuous, test = df_test_continuous, cl = df_train_target, k = k, prob = T)
table(df_test_target, knn_mod)
require(rpart)
require(rpart.plot)
tree_mod <- rpart(mpg_binary ~., data = df_train, method = "class")
rpart.plot(tree_mod, type = 3, digits = 3, fallen.leaves = TRUE)
print(tree_mod$variable.importance)
df_test_continuous = data.frame(df_test[ ,num_var])
df_train_continuous = data.frame(df_train[ ,num_var], df_train$mpg_binary)
colnames(df_train_continuous)[5] = "mpg_binary"
tree_mod2 <- rpart(mpg_binary ~., data = df_train_continuous)
rpart.plot(tree_mod2, type = 3, digits = 3, fallen.leaves = TRUE)
print(tree_mod2$variable.importance)
tree_mod_test2 <- predict(tree_mod2, df_test_continuous, type = "class")
table(df_test_target, tree_mod_test2)
set.seed(90210)
rand = runif(nrow(df_original))
df_test = df_all[1:40, ]
df_train = df_all[41:nrow(df), ]
df_all = df_original[order(rand), c(1:7, 10)]
df_test = df_all[1:40, ]
df_train = df_all[41:nrow(df), ]
tree_mod3 <- rpart(mpg_binary ~., data = df_train, method = "class")
rpart.plot(tree_mod3, type = 3, digits = 3, fallen.leaves = TRUE)
print(tree_mod3$variable.importance)
tree_mod_test3 <- predict(tree_mod3, df_test, type = "class")
rpart.plot(tree_mod3, type = 3, digits = 3, fallen.leaves = TRUE)
library(rmarkdown)
str(df_original)
length(unique(df_original$name))
View(df_original)
plot(df_original$name)
max(df_original$name)
count(df_original$name)
levels(df_original$name)
df = df_original
unique(df)
length(unique(df))
count(unique(df))
setwd("~/GitHub/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/Figures/Comparison")
rm(list = ls())
graphics.off()
source("../../Scripts/put_fig_letter.r")
source("../../Scripts/mycolors.R")
library(extrafont)
load("../../../Parametric_Uncertainty/Parametric_Uncertainty.RData")
png("fig3_new.png", width = 9, height = 5.5, unit = "in", res = 600)
#pdf("Baseline_Uncertainty_SLR_GEV2.pdf", width = 9.5, height = 5.5)
par(mfrow = c(2,2), mar = c(0, 1, 2, 0.75)+0.1, oma = c(3.5, 3, 0, 0.5)+0.1)
plot(X, (NPV_expected_losses.base/1e+06), type = 'l', col = myred,
xlab = NA,
ylab = expression(bold('Expected cost [million Guilders]')),
lwd = 3,
las = 1,
ylim = c(0,600),
xaxs="i",
xaxt='n')
lines(X, (costs.base/1e+06), col = myblue , lwd = 3)
lines(X, (total_costs.base/1e+06), col = 'black', lwd = 4)
points(min_cost_X, (total_costs.base[min_ind]/1e+06), cex = 1.5, pch = 19)
axis(side = 1, tck = -.045, labels = NA, lwd = 1.5)
axis(side = 2, tck = -.045, labels = NA, lwd = 1.5)
mtext('Expected cost [million Guilders]', side = 2, line = 3, cex = 0.9)
legend("topright",
lty = c(1, 1, 1, NA),
pch = c(NA, NA, NA, 20),
lwd = 3,
c("Discounted damages", "Investment costs", "Discounted total costs", "Minimum NPV total costs"),
col = c(myred, myblue, "black", "black"),
cex = 1,
bg = "white")
box(lwd = 1.3)
mtext("(A) van Dantzig (1956) baseline model structure", side = 3, line = 0.15, at = 0, adj = c(0,0), cex = 0.9)
text(min_cost_X, 200, labels = min_cost_X)
# (B) Parametric Uncertainty plot
# Load environment from van Dantzig analysis with parametric uncertainty
#load("../../../Parametric_Uncertainty/Parametric_Uncertainty.RData")
matplot(X, (NPV_expected_losses/1e+06), type = 'l', col = myredalpha05,
xlab = expression(bold("Dike height increase [m]")),
ylab = expression(bold('Expected cost [million Guilders]')),
las = 1,
lty = 1,
ylim = c(0,600),
xaxs="i",
xaxt = 'n',
yaxt = 'n')
lines(X, (mean_NPV_expected_losses/1e+06), col = "dark red", lwd = 3)
matlines(X, costs/1e+06, col = mybluealpha05, type = 'l', lty = 1)
lines(X, (mean_costs/1e+06), col = "blue", lwd = 3)
matlines(X, total_costs/1e+06, col = rgb(0, 0, 0, 0.02), lty = 1)
lines(X, (mean_total_costs/1e+06), col = "dark gray", lwd = 3)
points(min_cost_X_mean, (mean_total_costs[min_ind_mean]/1e+06), pch = 19, cex = 1.5, col = "dark gray")
box(lwd = 1.5)
axis(side = 1, tck = -.045, labels = NA, lwd = 1.5)
axis(side = 2, tck = -.045, labels = NA, lwd = 1.5)
mtext("(B) Addition of parametric uncertainties", side = 3, line = 0.15, at = 0, adj = c(0,0), cex = 0.9)
text(min_cost_X_mean, 200, labels = min_cost_X_mean)
load("../../../Uncertainty_SLR/Uncertainty_SLR.RData")
matplot(X, (NPV_expected_losses/1e+06), type = 'l', col = myredalpha05,
xlab = NA,
ylab = expression(bold('Expected cost (million Guilders)')),
las = 1,
lty = 1,
ylim = c(0,600),
xaxs="i")
lines(X, (mean_NPV_expected_losses/1e+06), col = "dark red", lwd = 3)
matlines(X, costs/1e+06, col = mybluealpha05, type = 'l', lty = 1)
lines(X, (mean_costs/1e+06), col = "blue", lwd = 3)
matlines(X, total_costs/1e+06, col = rgb(0, 0, 0, 0.02), lty = 1)
lines(X, (mean_total_costs/1e+06), col = "dark gray", lwd = 3)
points(min_cost_X_mean, (mean_total_costs[min_ind_mean]/1e+06), pch = 19, cex = 1.5, col = "dark gray")
box(lwd = 1.5)
axis(side = 1, tck = -.045, labels = NA, lwd = 1.5)
axis(side = 2, tck = -.045, labels = NA, lwd = 1.5)
mtext("Dike height increase [m]", side = 1, line = 2.5, cex = 0.9)
mtext('Expected cost [million Guilders]', side = 2, line = 3, cex = 0.9)
mtext("(C) Updated sea level rise model", side = 3, line = 0.15, at = 0, adj = c(0,0), cex = 0.9)
text(min_cost_X_mean, 225, labels = min_cost_X_mean)
load("../../SLR_GEV.RData")
matplot(X, (NPV_expected_losses/1e+06), type = 'l', col = myredalpha05,
xlab = expression(bold("Dike height increase [m]")),
ylab = expression(bold('Expected cost [million Guilders]')),
las = 1,
lty = 1,
ylim = c(0,600),
xaxs="i",
yaxt = 'n')
rm(list = ls())
load("../../SLR_GEV.RData")
rm(list = ls())
source("../../Scripts/put_fig_letter.r")
source("../../Scripts/mycolors.R")
library(extrafont)
# Baseline vs Uncertainty Figure
load("../../../Parametric_Uncertainty/Parametric_Uncertainty.RData")
# (A) Baseline plot
png("fig3_new.png", width = 9, height = 5.5, unit = "in", res = 600)
#pdf("Baseline_Uncertainty_SLR_GEV2.pdf", width = 9.5, height = 5.5)
par(mfrow = c(2,2), mar = c(0, 1, 2, 0.75)+0.1, oma = c(3.5, 3, 0, 0.5)+0.1)
plot(X, (NPV_expected_losses.base/1e+06), type = 'l', col = myred,
xlab = NA,
ylab = expression(bold('Expected cost [million Guilders]')),
lwd = 3,
las = 1,
ylim = c(0,600),
xaxs="i",
xaxt='n')
lines(X, (costs.base/1e+06), col = myblue , lwd = 3)
lines(X, (total_costs.base/1e+06), col = 'black', lwd = 4)
points(min_cost_X, (total_costs.base[min_ind]/1e+06), cex = 1.5, pch = 19)
axis(side = 1, tck = -.045, labels = NA, lwd = 1.5)
axis(side = 2, tck = -.045, labels = NA, lwd = 1.5)
mtext('Expected cost [million Guilders]', side = 2, line = 3, cex = 0.9)
legend("topright",
lty = c(1, 1, 1, NA),
pch = c(NA, NA, NA, 20),
lwd = 3,
c("Discounted damages", "Investment costs", "Discounted total costs", "Minimum NPV total costs"),
col = c(myred, myblue, "black", "black"),
cex = 1,
bg = "white")
box(lwd = 1.3)
mtext("(A) van Dantzig (1956) baseline model structure", side = 3, line = 0.15, at = 0, adj = c(0,0), cex = 0.9)
text(min_cost_X, 200, labels = min_cost_X)
# (B) Parametric Uncertainty plot
# Load environment from van Dantzig analysis with parametric uncertainty
#load("../../../Parametric_Uncertainty/Parametric_Uncertainty.RData")
matplot(X, (NPV_expected_losses/1e+06), type = 'l', col = myredalpha05,
xlab = expression(bold("Dike height increase [m]")),
ylab = expression(bold('Expected cost [million Guilders]')),
las = 1,
lty = 1,
ylim = c(0,600),
xaxs="i",
xaxt = 'n',
yaxt = 'n')
lines(X, (mean_NPV_expected_losses/1e+06), col = "dark red", lwd = 3)
matlines(X, costs/1e+06, col = mybluealpha05, type = 'l', lty = 1)
lines(X, (mean_costs/1e+06), col = "blue", lwd = 3)
matlines(X, total_costs/1e+06, col = rgb(0, 0, 0, 0.02), lty = 1)
lines(X, (mean_total_costs/1e+06), col = "dark gray", lwd = 3)
points(min_cost_X_mean, (mean_total_costs[min_ind_mean]/1e+06), pch = 19, cex = 1.5, col = "dark gray")
box(lwd = 1.5)
axis(side = 1, tck = -.045, labels = NA, lwd = 1.5)
axis(side = 2, tck = -.045, labels = NA, lwd = 1.5)
mtext("(B) Addition of parametric uncertainties", side = 3, line = 0.15, at = 0, adj = c(0,0), cex = 0.9)
text(min_cost_X_mean, 200, labels = min_cost_X_mean)
# (C) Sea level rise module plot
# Load environment from van Dantzig analysis with sea level rise module
load("../../../Uncertainty_SLR/Uncertainty_SLR.RData")
matplot(X, (NPV_expected_losses/1e+06), type = 'l', col = myredalpha05,
xlab = NA,
ylab = expression(bold('Expected cost (million Guilders)')),
las = 1,
lty = 1,
ylim = c(0,600),
xaxs="i")
lines(X, (mean_NPV_expected_losses/1e+06), col = "dark red", lwd = 3)
matlines(X, costs/1e+06, col = mybluealpha05, type = 'l', lty = 1)
lines(X, (mean_costs/1e+06), col = "blue", lwd = 3)
matlines(X, total_costs/1e+06, col = rgb(0, 0, 0, 0.02), lty = 1)
lines(X, (mean_total_costs/1e+06), col = "dark gray", lwd = 3)
points(min_cost_X_mean, (mean_total_costs[min_ind_mean]/1e+06), pch = 19, cex = 1.5, col = "dark gray")
box(lwd = 1.5)
axis(side = 1, tck = -.045, labels = NA, lwd = 1.5)
axis(side = 2, tck = -.045, labels = NA, lwd = 1.5)
mtext("Dike height increase [m]", side = 1, line = 2.5, cex = 0.9)
mtext('Expected cost [million Guilders]', side = 2, line = 3, cex = 0.9)
mtext("(C) Updated sea level rise model", side = 3, line = 0.15, at = 0, adj = c(0,0), cex = 0.9)
text(min_cost_X_mean, 225, labels = min_cost_X_mean)
# (D) Storm surge module plot
# Load environment from van Dantzig analysis with sea level rise module
load("../../SLR_GEV.RData")
matplot(X, (NPV_expected_losses/1e+06), type = 'l', col = myredalpha05,
xlab = expression(bold("Dike height increase [m]")),
ylab = expression(bold('Expected cost [million Guilders]')),
las = 1,
lty = 1,
ylim = c(0,600),
xaxs="i",
yaxt = 'n')
dev.off()
dev.off()
rm(list = ls())
graphics.off()
